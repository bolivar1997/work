{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imgaug import augmenters as iaa\n",
    "import json\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = './data/GeneratorData/'\n",
    "IMAGES_EXT = ['.jpg', '.png']\n",
    "DATASET_SHAPE = (64, 64)\n",
    "\n",
    "\n",
    "def list_files(d, ext_list):\n",
    "    if not os.path.exists(d) or not os.listdir(d):\n",
    "        return tuple()\n",
    "    return filter(lambda x: os.path.isfile(os.path.join(d, x))\n",
    "                            and os.path.splitext(x)[1].lower() in ext_list, os.listdir(d))\n",
    "\n",
    "\n",
    "def get_dewarped_patch(img, pols, shape=(64, 64)):\n",
    "    # Crops a polygon (namely, a rectangle containing a bubble) with given vertices from an image'\n",
    "    assert len(img.shape) == 2, \"Make sure that the image is in greyscale\"\n",
    "    source = np.float32([pols[0], pols[1], pols[3]])\n",
    "    destination = np.float32([[0, 0], [shape[1], 0], [0, shape[0]]])\n",
    "    # Destination can be with gap:\n",
    "    m = cv2.getAffineTransform(source, destination)\n",
    "    dst = cv2.warpAffine(img, m, shape, flags=cv2.INTER_LANCZOS4)\n",
    "    return dst\n",
    "\n",
    "\n",
    "def show_images(images, labels):\n",
    "    img = np.concatenate(images, axis=1).reshape(-1, images[0].shape[1] * len(images))\n",
    "    fig, ax = plt.subplots(1, figsize=(40, 4))\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    plt.title(str(labels))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_image_data(data_path, image_path):\n",
    "\n",
    "    bubbles = []\n",
    "    labels = []\n",
    "\n",
    "    src_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    markup_path_prefix =os.path.splitext(image_path)[0]\n",
    "    try:\n",
    "        with open(markup_path_prefix + '_pols.json', 'r') as mf:\n",
    "            polygons = json.load(mf)\n",
    "\n",
    "        with open(markup_path_prefix + '_ethalon.json', 'r') as mf:\n",
    "            pol_labels = json.load(mf)\n",
    "\n",
    "        return src_image, polygons, pol_labels\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    return src_image, bubbles, labels\n",
    "\n",
    "\n",
    "def parse_dataset(data_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for f in list_files(data_path, IMAGES_EXT):\n",
    "        image_path = os.path.join(data_path, f)\n",
    "        image, polygons, pol_labels = get_image_data(image_path)\n",
    "        for i, p in enumerate(polygons):\n",
    "            bubble = get_dewarped_patch(image, p, DATASET_SHAPE)\n",
    "            bubble = np.expand_dims(bubble, axis=3)\n",
    "            images.append(bubble)\n",
    "\n",
    "        labels.extend(pol_labels)\n",
    "\n",
    "    parsed_images = np.array(images)\n",
    "    parsed_labels = np.array(labels)\n",
    "    ids = [i for i in range(len(images))]\n",
    "\n",
    "    return parsed_labels, parsed_images, ids\n",
    "\n",
    "\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        sometimes(iaa.Crop(percent=(0, 0.03))),\n",
    "        sometimes(iaa.Affine(\n",
    "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "            rotate=(-20, 20),\n",
    "            shear=(-8, 8),\n",
    "            order=[0, 1],\n",
    "            cval=255,\n",
    "            mode=['wrap', 'constant', 'symmetric', 'reflect']\n",
    "        )),\n",
    "        iaa.SomeOf((0, 5),\n",
    "                   [\n",
    "\n",
    "                       iaa.OneOf([\n",
    "                           iaa.GaussianBlur((0, 1.0)),\n",
    "                           iaa.AverageBlur(k=(2, 3)),\n",
    "                       ]),\n",
    "\n",
    "                       iaa.Sharpen(alpha=(0, 0.2), lightness=(0.75, 1.3)),\n",
    "                       iaa.Fliplr(0.2),\n",
    "                       iaa.Flipud(0.2),\n",
    "\n",
    "                       iaa.Emboss(alpha=(0, 1.0), strength=(0.3, 1.3)),\n",
    "                       sometimes(iaa.OneOf([\n",
    "                           iaa.EdgeDetect(alpha=(0, 0.7)),\n",
    "                           iaa.DirectedEdgeDetect(\n",
    "                               alpha=(0, 0.7), direction=(0.0, 1.0)\n",
    "                           ),\n",
    "                       ])),\n",
    "\n",
    "                       iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.03 * 255)),\n",
    "\n",
    "                       iaa.Add((-10, 10)),\n",
    "\n",
    "                       iaa.Multiply((0.7, 1.3)),\n",
    "\n",
    "                       iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5),\n",
    "\n",
    "                       sometimes(\n",
    "                           iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)\n",
    "                       ),\n",
    "\n",
    "                   ],\n",
    "                   random_order=True\n",
    "                   )\n",
    "    ],\n",
    "    random_order=True\n",
    ")\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Generates data for Keras\"\"\"\n",
    "\n",
    "    def __init__(self, file_names, pattern_augm, client_image_augm, bubble_augm, n_channels=1,\n",
    "                 batch_size=32, bubbles_num=800, shuffle=True):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.bubbles_num = bubbles_num\n",
    "        self.pattern_augm = pattern_augm\n",
    "        self.client_image_augm = client_image_augm\n",
    "        self.bubble_augm = bubble_augm\n",
    "        self.file_names = file_names\n",
    "        self.shuffle = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.temp_images = np.array([])\n",
    "        self.images_info = []\n",
    "        self.parse_big_images()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return int(np.floor(len(self.file_names * self.bubbles_num) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\"\"\"\n",
    "        if index == 0:\n",
    "            self.on_epoch_end()\n",
    "\n",
    "        file_num = (index * self.batch_size) // self.bubbles_num\n",
    "        pos_in_file = (index * self.batch_size) % self.bubbles_num\n",
    "\n",
    "        if pos_in_file + self.batch_size > self.bubbles_num:\n",
    "            pos_in_file = self.bubbles_num - self.batch_size\n",
    "\n",
    "        x, y = self.__data_generation(self.temp_images[file_num], pos_in_file)\n",
    "        return x, y, index\n",
    "\n",
    "    def parse_big_images(self):\n",
    "        x = []\n",
    "\n",
    "        for i in range(len(self.file_names)):\n",
    "            img1, polygons1, labels1 = get_image_data(DATA_PATH, self.file_names[i][0])\n",
    "            img2, polygons2, labels2 = get_image_data(DATA_PATH, self.file_names[i][1])\n",
    "\n",
    "            x.append([(img1, polygons1, labels1), (img2, polygons2, labels2)])\n",
    "\n",
    "        self.images_info = x\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        tmp = copy.deepcopy(self.images_info)\n",
    "        result = []\n",
    "\n",
    "        for i in range(len(tmp)):\n",
    "            pair = tmp[i]\n",
    "\n",
    "            image_base = self.pattern_augm.augment_image(pair[0][0])\n",
    "            image_client = self.client_image_augm.augment_image(pair[1][0])\n",
    "            result.append(((image_base, pair[0][1], pair[0][2]), (image_client, pair[1][1], pair[1][2])))\n",
    "\n",
    "        self.temp_images = result\n",
    "\n",
    "    def __data_generation(self, pair_images, batch_start_position):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"\n",
    "        x = np.empty((self.batch_size, 2, DATASET_SHAPE[0], DATASET_SHAPE[1], self.n_channels))\n",
    "        y = np.empty(self.batch_size, dtype=int)\n",
    "\n",
    "        token = 0\n",
    "        for j in range(batch_start_position, batch_start_position + self.batch_size):\n",
    "            curr_pair = np.empty((2, DATASET_SHAPE[0], DATASET_SHAPE[1], self.n_channels))\n",
    "            for ind in range(0, 2):\n",
    "                polygon = pair_images[ind][1][j]\n",
    "                bubble = get_dewarped_patch(pair_images[ind][0], polygon, DATASET_SHAPE)\n",
    "                bubble = np.expand_dims(bubble, axis=3)\n",
    "\n",
    "                curr_pair[ind] = bubble\n",
    "\n",
    "            # take second images of pair, take label with j-th index\n",
    "            y[token] = pair_images[1][2][j]\n",
    "            x[token] = curr_pair\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "pairs = [['./data/GeneratorData/2_3.JPG', './data/GeneratorData/2_3pattern.JPG']]\n",
    "\n",
    "training_generator = DataGenerator(pairs, seq, seq, seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 2, 64, 64, 1) (32,) 0\n",
      "(32, 2, 64, 64, 1) (32,) 1\n",
      "(32, 2, 64, 64, 1) (32,) 2\n",
      "(32, 2, 64, 64, 1) (32,) 3\n",
      "(32, 2, 64, 64, 1) (32,) 4\n",
      "(32, 2, 64, 64, 1) (32,) 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bolivar1997/PycharmProjects/untitled/venv/lib/python3.5/site-packages/ipykernel/__main__.py:210: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    }
   ],
   "source": [
    "def show_images(images, labels):\n",
    "    img = np.concatenate(images, axis=1).reshape(-1, images[0].shape[1] * len(images))\n",
    "    fig, ax = plt.subplots(1, figsize=(40, 4))\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    plt.title(str(labels))\n",
    "    plt.show()\n",
    "\n",
    "token = 0\n",
    "\n",
    "\n",
    "for x_batch, y_batch, id in training_generator:\n",
    "    print(x_batch.shape, y_batch.shape, id)\n",
    "    \n",
    "    images = x_batch[:, 0, :, :, :]\n",
    "    token += 1\n",
    "    show_images(iam)\n",
    "    if token > 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
